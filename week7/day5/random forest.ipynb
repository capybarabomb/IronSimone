{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b0cae31",
   "metadata": {},
   "source": [
    "# Lab | Classification, Handling Imbalanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "042f1ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.datasets import load_iris, load_breast_cancer\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0312cd0",
   "metadata": {},
   "source": [
    "##Â Round 1\n",
    "- Import the required libraries and modules that you would need.\n",
    "- Read that data into Python and call the dataframe `churnData`.\n",
    "- Check the datatypes of all the columns in the data. You would see that the column `TotalCharges` is object type. Convert this column into numeric type using `pd.to_numeric` function.\n",
    "- Check for null values in the dataframe. Replace the null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a98f5992",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/DATA_Customer-Churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d131ed88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7043 entries, 0 to 7042\n",
      "Data columns (total 16 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   gender            7043 non-null   object \n",
      " 1   SeniorCitizen     7043 non-null   int64  \n",
      " 2   Partner           7043 non-null   object \n",
      " 3   Dependents        7043 non-null   object \n",
      " 4   tenure            7043 non-null   int64  \n",
      " 5   PhoneService      7043 non-null   object \n",
      " 6   OnlineSecurity    7043 non-null   object \n",
      " 7   OnlineBackup      7043 non-null   object \n",
      " 8   DeviceProtection  7043 non-null   object \n",
      " 9   TechSupport       7043 non-null   object \n",
      " 10  StreamingTV       7043 non-null   object \n",
      " 11  StreamingMovies   7043 non-null   object \n",
      " 12  Contract          7043 non-null   object \n",
      " 13  MonthlyCharges    7043 non-null   float64\n",
      " 14  TotalCharges      7043 non-null   object \n",
      " 15  Churn             7043 non-null   object \n",
      "dtypes: float64(1), int64(2), object(13)\n",
      "memory usage: 880.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "049980dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.TotalCharges = pd.to_numeric(df.TotalCharges, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95409481",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dcdc7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_df = df.select_dtypes(include=['int64', 'float64'])\n",
    "cat_df = df.select_dtypes(include=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb11d51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df = cat_df.drop(columns='Churn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75c0a533",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df_dummified = pd.get_dummies(cat_df, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7870f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([num_df, cat_df_dummified], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5c407f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.Churn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157b2f10",
   "metadata": {},
   "source": [
    "## Split the data into a training set and a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4875e0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "TT_SPLIT = 0.2     # ratio train/test size\n",
    "RAND_STATE = 123   # specifies a sampling for repeatable results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6f6ef8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=TT_SPLIT,random_state=RAND_STATE) # splitting the data into train and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e04e40",
   "metadata": {},
   "source": [
    "## Scale the features either by using normalizer or a standard scaler.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01dbca01",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler() \n",
    "\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08942414",
   "metadata": {},
   "source": [
    "## Comparing 3 classification models BEFORE smote\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd96c8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Decision Tree': 0.7358902507639862, 'K Neighbors': 0.764819913601397, 'Logistic Regression': 0.7976570564900607}\n"
     ]
    }
   ],
   "source": [
    "model1 = DecisionTreeClassifier(max_depth=15)\n",
    "model2 = KNeighborsClassifier(n_neighbors=5,weights='uniform')\n",
    "model3 = LogisticRegression()\n",
    "\n",
    "model_pipeline = [model1, model2, model3]\n",
    "model_names = ['Decision Tree', 'K Neighbors', 'Logistic Regression']\n",
    "scores = {}\n",
    "i=0\n",
    "for model in model_pipeline:\n",
    "    mean_score = np.mean(cross_val_score(model, X_train_scaled, y_train, cv=5))\n",
    "    scores[model_names[i]] = mean_score\n",
    "    i = i+1\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c31b53",
   "metadata": {},
   "source": [
    "## Upsampling using SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b10265f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7d6e82d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     4159\n",
       "Yes    1475\n",
       "Name: Churn, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8fbfa8f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Yes    4159\n",
       "No     4159\n",
       "Name: Churn, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sm, y_sm = smote.fit_resample(X_train_scaled, y_train)\n",
    "y_sm.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d08102b",
   "metadata": {},
   "source": [
    "## Comparing 3 classification models AFTER smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48fe806d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Decision Tree': 0.7672576784310098, 'K Neighbors': 0.7856480410749804, 'Logistic Regression': 0.7650877844719923}\n"
     ]
    }
   ],
   "source": [
    "model1 = DecisionTreeClassifier(max_depth=15)\n",
    "model2 = KNeighborsClassifier(n_neighbors=5,weights='uniform')\n",
    "model3 = LogisticRegression()\n",
    "\n",
    "model_pipeline = [model1, model2, model3]\n",
    "model_names = ['Decision Tree', 'K Neighbors', 'Logistic Regression']\n",
    "scores = {}\n",
    "i=0\n",
    "for model in model_pipeline:\n",
    "    mean_score = np.mean(cross_val_score(model, X_sm, y_sm, cv=5))\n",
    "    scores[model_names[i]] = mean_score\n",
    "    i = i+1\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c78a14a",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "66db03c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'min_samples_split': [20],\n",
    "    'min_samples_leaf' : [10],\n",
    "    'max_features': ['sqrt']\n",
    "    ##'max_samples' : ['None', 0.5],\n",
    "    ##'max_depth':[3,5,10],\n",
    "    ## 'bootstrap':[True,False]\n",
    "    }\n",
    "clf = RandomForestClassifier(random_state=RAND_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "60318db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(clf, param_grid, cv=5,return_train_score=True,n_jobs=-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "df4d1a3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=123),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'max_features': ['sqrt'], 'min_samples_leaf': [10],\n",
       "                         'min_samples_split': [20], 'n_estimators': [50, 100]},\n",
       "             return_train_score=True)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_sm, y_sm.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "235a5340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 'sqrt',\n",
       " 'min_samples_leaf': 10,\n",
       " 'min_samples_split': 20,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = grid_search.best_params_ #To check the best set of parameters returned\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6eaad918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8046444244645914\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "clf = RandomForestClassifier(random_state=RAND_STATE, **best_params)\n",
    "cross_val_scores = cross_val_score(clf, X_sm, y_sm, cv=5)\n",
    "print(np.mean(cross_val_scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
